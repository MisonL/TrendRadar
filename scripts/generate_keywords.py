# coding=utf-8
"""
AI å…³é”®è¯è‡ªåŠ¨ç”Ÿæˆå·¥å…·

é€šè¿‡ AI ä¸ºæŒ‡å®šé¢†åŸŸç”Ÿæˆ frequency_words.txt è§„åˆ™ã€‚
"""

import sys
import os
import asyncio
import argparse
from pathlib import Path

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent / "src"))

from trendradar.core.loader import load_config
from trendradar.core.llm_service import LLMService

PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æä¸“å®¶ã€‚æˆ‘éœ€è¦ä½ ä¸ºä¸€ä¸ªæ–°é—»ç›‘æµ‹ç³»ç»Ÿç”Ÿæˆâ€œé¢‘ç‡è¯è¿‡æ»¤ä¸åˆ†ç±»è§„åˆ™â€ã€‚

ã€ç›®æ ‡é¢†åŸŸã€‘ï¼š{domain}

ã€è§„åˆ™è¯­æ³•è¯´æ˜ã€‘ï¼š
1. åˆ†ç±»åŒ…å«é€»è¾‘ï¼š/æ­£åˆ™è¡¨è¾¾å¼/ => åˆ†ç±»åç§° (åªæœ‰å‘½ä¸­æ­¤è§„åˆ™çš„æ–°é—»æ‰ä¼šä¿ç•™å¹¶å½’ç±»)
2. å¿…é¡»è¯é€»è¾‘ï¼š+è¯ (è¯¥ç»„å†…çš„æ‰€æœ‰å¿…é¡»è¯éƒ½åŒ¹é…æ‰ç®—ä¸­)
3. æ’é™¤é€»è¾‘ï¼š!è¯ (å‘½ä¸­æ­¤è¯çš„æ–°é—»å°†è¢«ä¸¢å¼ƒï¼Œä¼˜å…ˆçº§æœ€é«˜)

ã€è¦æ±‚ã€‘ï¼š
1. è¯·ç”Ÿæˆ 3-5 ä¸ªç»†åˆ†è¯é¢˜çš„åŒ…å«é€»è¾‘æ­£åˆ™å’Œåˆ†ç±»ã€‚
2. è¯·é¢å¤–ç”Ÿæˆ 3-5 ä¸ªåœ¨è¯¥é¢†åŸŸå¸¸è§çš„å™ªéŸ³è¯ï¼ˆæ’é™¤é€»è¾‘ï¼‰ã€‚
3. åªè¾“å‡ºè§„åˆ™å†…å®¹ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€‚
4. æ¯è¡Œä¸€æ¡è§„åˆ™ã€‚

ã€è¾“å‡ºç¤ºä¾‹ã€‘ï¼š
/æ¯”ç‰¹å¸|ä»¥å¤ªåŠ|åŠ å¯†è´§å¸|Web3/ => åŠ å¯†è´§å¸è¶‹åŠ¿
/æ•°å­—è´§å¸|äº¤æ˜“æ‰€|æŒ–çŸ¿|ä¸­æœ¬èª/ => å¸åœˆåŠ¨æ€
!è™šæ‹Ÿè´§å¸å¥—è·¯
!æ€çŒªç›˜

ç°åœ¨ï¼Œè¯·ä¸ºã€{domain}ã€‘é¢†åŸŸç”Ÿæˆè§„åˆ™ï¼š
"""

async def main():
    parser = argparse.ArgumentParser(description="AI å…³é”®è¯è‡ªåŠ¨ç”Ÿæˆå·¥å…·")
    parser.add_argument("domain", help="æƒ³è¦ç”Ÿæˆçš„é¢†åŸŸæè¿°ï¼ˆä¾‹å¦‚ï¼šä½ç©ºç»æµã€åŠå¯¼ä½“ç­‰ï¼‰")
    parser.add_argument("--append", action="store_true", help="è¿½åŠ åˆ°ç°æœ‰æ–‡ä»¶è€Œä¸æ˜¯è¦†ç›–")
    parser.add_argument("-y", "--yes", action="store_true", help="è‡ªåŠ¨ç¡®è®¤å¹¶ä¸å†æç¤º")
    args = parser.parse_args()

    # 1. åŠ è½½é…ç½®å’Œ LLM
    try:
        config = load_config()
        llm = LLMService(config)
        
        if not llm.is_enabled():
            print("âŒ é”™è¯¯: LLM æœåŠ¡æœªå¯ç”¨ã€‚è¯·åœ¨ .env ä¸­è®¾ç½® LLM_ENABLED=true å¹¶é…ç½®ç›¸å…³å‚æ•°ã€‚")
            return
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
        return

    # 2. ç”Ÿæˆå…³é”®è¯
    print(f"ğŸš€ æ­£åœ¨ä¸ºé¢†åŸŸã€{args.domain}ã€‘ç”Ÿæˆå…³é”®è¯é…ç½®...")
    prompt = PROMPT_TEMPLATE.format(domain=args.domain)
    
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šè§„åˆ™ç”ŸæˆåŠ©æ‰‹ï¼Œåªè¾“å‡º frequency_words.txt æ ¼å¼çš„è§„åˆ™ã€‚"
    response = await llm.ask(prompt, system_prompt=system_prompt)
    
    if "Request failed" in response:
        print(f"âŒ AI ç”Ÿæˆå¤±è´¥: {response}")
        return

    # æ¸…ç†å“åº”å†…å®¹
    lines = [line.strip() for line in response.split("\n") if line.strip() and not line.startswith("```")]
    cleaned_content = "\n".join(lines)

    print("\n" + "="*40)
    print("âœ¨ AI ç”Ÿæˆçš„è§„åˆ™é¢„è§ˆï¼š")
    print("-" * 40)
    print(cleaned_content)
    print("="*40 + "\n")

    # 3. å†™å…¥æ–‡ä»¶
    if args.yes:
        confirm = 'y'
    else:
        confirm = input("âš ï¸ æ˜¯å¦ç¡®è®¤å°†ä¸Šè¿°è§„åˆ™å†™å…¥ config/frequency_words.txt? (y/n): ")
    
    if confirm.lower() != 'y':
        print("ğŸ›‘ å·²å–æ¶ˆæ“ä½œã€‚")
        return

    target_path = Path("config/frequency_words.txt")
    
    # å¦‚æœç›®æ ‡ç›®å½•ä¸å­˜åœ¨ï¼Œå…ˆåˆ›å»º
    target_path.parent.mkdir(parents=True, exist_ok=True)

    mode = "a" if args.append and target_path.exists() else "w"
    
    try:
        with open(target_path, mode, encoding="utf-8") as f:
            if mode == "a":
                f.write("\n\n")
                f.write(f"# --- AI å¢åŠ é¢†åŸŸ: {args.domain} ---\n")
            f.write(cleaned_content)
            f.write("\n")
        
        print(f"âœ… æˆåŠŸå†™å…¥ {target_path} (æ¨¡å¼: {'è¿½åŠ ' if mode == 'a' else 'é‡å†™'})")
    except Exception as e:
        print(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
